{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpB+6bW71g9ATPxKpTCy5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vieira-Marola/Spam_Detection/blob/main/Phishing_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZH3jes0hlB",
        "outputId": "bb0aabce-cc7d-4caa-c157-6c34b902452c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openml\n",
            "  Downloading openml-0.15.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting liac-arff>=2.4.0 (from openml)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict (from openml)\n",
            "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from openml) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from openml) (1.6.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from openml) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from openml) (2.2.2)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.12/dist-packages (from openml) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from openml) (2.0.2)\n",
            "Collecting minio (from openml)\n",
            "  Downloading minio-7.2.20-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from openml) (18.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openml) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from openml) (25.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->openml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->openml) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->openml) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->openml) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->openml) (3.6.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from minio->openml) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from minio->openml) (2025.11.12)\n",
            "Collecting pycryptodome (from minio->openml)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from minio->openml) (4.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from minio->openml) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->openml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->openml) (3.11)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->minio->openml) (25.1.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.23)\n",
            "Downloading openml-0.15.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading minio-7.2.20-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=98c772021243a24258eb54867d38aa3bdf21c26faa1ca228f89333c795a606c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/ac/cf/c2919807a5c623926d217c0a18eb5b457e5c19d242c3b5963a\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: xmltodict, pycryptodome, liac-arff, minio, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.2.20 openml-0.15.1 pycryptodome-3.23.0 xmltodict-1.0.2\n",
            "Dataset loaded successfully. Displaying the first 5 rows:\n",
            "                                       text_combined label\n",
            "0  hpl nom may 25 2001 see attached file hplno 52...     0\n",
            "1  nom actual vols 24 th forwarded sabrae zajac h...     0\n",
            "2  enron actuals march 30 april 1 201 estimated a...     0\n",
            "3  hpl nom may 30 2001 see attached file hplno 53...     0\n",
            "4  hpl nom june 1 2001 see attached file hplno 60...     0\n"
          ]
        }
      ],
      "source": [
        "!pip install openml\n",
        "import openml\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset using its data_id\n",
        "dataset = openml.datasets.get_dataset(46099)\n",
        "\n",
        "# Get the data in a pandas DataFrame format\n",
        "X, y, _, _ = dataset.get_data(dataset_format=\"dataframe\")\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"Dataset loaded successfully. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUW0ZwT1TXv",
        "outputId": "08a16005-d5ba-4377-e5ca-3dd67b13aef1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 82486 entries, 0 to 82485\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype   \n",
            "---  ------         --------------  -----   \n",
            " 0   text_combined  82486 non-null  object  \n",
            " 1   label          82486 non-null  category\n",
            "dtypes: category(1), object(1)\n",
            "memory usage: 725.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(include='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR8Hs10z1W2p",
        "outputId": "5da40a9c-0595-4569-c4da-f2581b20fc4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            text_combined  label\n",
            "count                                               82486  82486\n",
            "unique                                              82078      2\n",
            "top     charity sees need cost dear friend read want f...      1\n",
            "freq                                                    3  42891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeHgFxeW1agL",
        "outputId": "cc7c9e0d-8e77-4910-b448-40b6220feafe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "text_combined    0\n",
            "label            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_combined'] = df['text_combined'].str.lower()\n",
        "print(\"Converted 'text_combined' column to lowercase.\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqK7bWs11c2o",
        "outputId": "0eecd9c7-3131-41f2-9d6a-5ad4882e504c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 'text_combined' column to lowercase.\n",
            "                                       text_combined label\n",
            "0  hpl nom may 25 2001 see attached file hplno 52...     0\n",
            "1  nom actual vols 24 th forwarded sabrae zajac h...     0\n",
            "2  enron actuals march 30 april 1 201 estimated a...     0\n",
            "3  hpl nom may 30 2001 see attached file hplno 53...     0\n",
            "4  hpl nom june 1 2001 see attached file hplno 60...     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df['text_combined'] = df['text_combined'].apply(remove_punctuation)\n",
        "print(\"Removed punctuation from 'text_combined' column.\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfIiSb581f0x",
        "outputId": "302468cf-e941-4101-d11d-fe86d9f39425"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed punctuation from 'text_combined' column.\n",
            "                                       text_combined label\n",
            "0  hpl nom may 25 2001 see attached file hplno 52...     0\n",
            "1  nom actual vols 24 th forwarded sabrae zajac h...     0\n",
            "2  enron actuals march 30 april 1 201 estimated a...     0\n",
            "3  hpl nom may 30 2001 see attached file hplno 53...     0\n",
            "4  hpl nom june 1 2001 see attached file hplno 60...     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribution of the target variable 'label':\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"\\nPercentage distribution of the target variable 'label':\")\n",
        "print(df['label'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDMob12Z1jwF",
        "outputId": "22e16666-6ecf-40c7-8e0b-82e9849e3a61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of the target variable 'label':\n",
            "label\n",
            "1    42891\n",
            "0    39595\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage distribution of the target variable 'label':\n",
            "label\n",
            "1    51.997915\n",
            "0    48.002085\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df['text_combined']\n",
        "y = df['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Data split into training and testing sets.\")\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETi7Axlf1msR",
        "outputId": "e76a9a0b-3c4d-465b-eeea-f055bef40627"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split into training and testing sets.\n",
            "Shape of X_train: (65988,)\n",
            "Shape of X_test: (16498,)\n",
            "Shape of y_train: (65988,)\n",
            "Shape of y_test: (16498,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limiting features to manage complexity\n",
        "\n",
        "# Fit and transform X_train\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform X_test\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF Vectorization completed.\")\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_tfidf: {X_test_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcmBZFXV1rCI",
        "outputId": "e083bfad-b054-4cdd-b05e-dbaba8309624"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorization completed.\n",
            "Shape of X_train_tfidf: (65988, 5000)\n",
            "Shape of X_test_tfidf: (16498, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6fUznYy10cl",
        "outputId": "b25062ca-2467-485b-c653-06a55f33cd25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"Predictions on the test set completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkUji3SL14V3",
        "outputId": "1e20ea0e-626e-4918-9450-dac74a92a6aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on the test set completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Using 'weighted' for multi-class/imbalanced binary classification\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Model F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE4nHBfK174v",
        "outputId": "c8a4dd61-e260-4f3d-8ff4-f1323c1d0fd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9824\n",
            "Model F1-score: 0.9824\n"
          ]
        }
      ]
    }
  ]
}